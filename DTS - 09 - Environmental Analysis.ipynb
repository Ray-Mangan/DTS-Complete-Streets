{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**DTS - Complete Streets** *Right-of-Way Widths for Planned Street Improvements*\n",
    "\n",
    "\n",
    "\n",
    "# 09 - Environmental Analysis\n",
    "\n",
    "**Author:** rmangan\n",
    "\n",
    "---\n",
    "\n",
    "**Purpose:**\n",
    "\n",
    "Calculate metrics related to Economic Justice and Sea Level Rise Exposure Area \n",
    "\n",
    "**This script performs the following functions:**\n",
    "\n",
    "1. Add and calculate fields to indicate length and percent of segment inside Economic Justice polygons\n",
    "\n",
    "2. Add and calcualte fields to indicate length and percent of segment inside Sea Level Rise Exposre Area polygons\n",
    "\n",
    "\n",
    "**Global Assumptions and Notes:**\n",
    "1. Economic Justice Dataset (requires written request to Oahu MPO)\n",
    "    1. Homepage = https://www.oahumpo.org/projects/planning-studies/title-vi-and-environmental-justice-monitoring/\n",
    "2. Sea Level Rise Exposure Area Dataset\n",
    "    1. Metadata = https://files.hawaii.gov/dbedt/op/gis/data/slr_exposure_area_3_pt_2_ft.html\n",
    "    2. Data  = https://files.hawaii.gov/dbedt/op/gis/data/slr_exposure_area_all.shp.zip\n",
    "\n",
    "**Non-Standard Python Modules utilized:**\n",
    "1. arcpy 2.7 - used for geo-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import modules\n",
    "import arcpy\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set environment setttings\n",
    "arcpy.env.workspace = \"Z:\\H\\Honolulu_DTS\\D3409300_RailActivation\\GeoData\\GDB\\modal\\Modal_Composite4.gdb\"\n",
    "arcpy.env.overwriteOutput = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define variables\n",
    "input_gdb_path = r\"\\\\dc1vs01\\GISProj\\H\\Honolulu_DTS\\D3409300_RailActivation\\GeoData\\GDB\\Input_Data.gdb\"\n",
    "\n",
    "scratch_gdb_path = r\"\\\\dc1vs01\\GISProj\\H\\Honolulu_DTS\\D3409300_RailActivation\\GeoData\\GDB\\scratch_GDBs\\modal_composite_scratch.gdb\"\n",
    "\n",
    "output_gdb_path = r\"\\\\dc1vs01\\GISProj\\H\\Honolulu_DTS\\D3409300_RailActivation\\GeoData\\GDB\\scratch_GDBs\\modal_composite_output.gdb\"\n",
    "\n",
    "\n",
    "# Input Datasets\n",
    "\n",
    "modal_composite = r\"\\\\dc1vs01\\GISProj\\H\\Honolulu_DTS\\D3409300_RailActivation\\GeoData\\GDB\\Modal\\Modal Composite 5_3.gdb\\modal_composite_05_3\"\n",
    "\n",
    "EJ = r\"Z:\\H\\Honolulu_DTS\\D3409300_RailActivation\\Transfer\\Communications\\From\\External\\20211005_DTS_T6EJ\\T6EJ_Data.gdb\\OahuMPO_EJ_Areas_Updated_2016_Block_Groups\"\n",
    "\n",
    "SLR = r\"\\\\dc1vs01\\GISProj\\H\\Honolulu_DTS\\D3409300_RailActivation\\GeoData\\GDB\\Input_Data.gdb\\SLR\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def percent(input_dataset, poly_dataset, new_length_field, new_length_alias, new_percent_field, new_percent_alias):\n",
    "    #take an input line dataset and calculate length and  percentage by length that each line segment\n",
    "    #inersects with a polygon dataset\n",
    "    #this function adds 2 new fields to the input dataset  \n",
    "    \n",
    "    \n",
    "    #create lyr for analysis\n",
    "    print(\"create analysis lyr...\")\n",
    "    lyr = arcpy.management.MakeFeatureLayer(poly_dataset, \"lyr\", where_clause = \"\")\n",
    "    \n",
    "    #dissolve polygon lyr to single feature\n",
    "    print(\"dissolving polygon data...\")\n",
    "    dissolve_output = os.path.join(scratch_gdb_path, \"dissolve\")\n",
    "    dissolve = arcpy.management.Dissolve(lyr, dissolve_output)\n",
    "    \n",
    "    #intersect line data w/ polygon dissolve output\n",
    "    #output is lines that are inside polygon areas\n",
    "    print(\"intersecting polygon data with lines...\")\n",
    "    intersect_output = os.path.join(scratch_gdb_path, \"intersect\")\n",
    "    intersect = arcpy.analysis.Intersect([input_dataset, dissolve], intersect_output)\n",
    "    \n",
    "    #add length field to intersection output if it doesnt already exist\n",
    "    print(\"add {} field...\".format(new_length_field))\n",
    "     \n",
    "    list_fields = arcpy.ListFields(intersect)\n",
    "    field_names = [i.name for i in list_fields]\n",
    "\n",
    "    if new_length_field in field_names:\n",
    "        print(\"{} field already exists\".format(new_length_field))\n",
    "    else:  \n",
    "        print(\"adding field...\")\n",
    "        arcpy.AddField_management(intersect,\n",
    "                                  field_name = new_length_field,\n",
    "                                  field_type=\"FLOAT\",\n",
    "                                  field_alias = new_length_alias)\n",
    "        \n",
    "    #calc length field from shape.length with update cursor\n",
    "    print(\"calc field from shape.length...\")\n",
    "    with arcpy.da.UpdateCursor(intersect,[\"Shape_Length\", new_length_field]) as cursor:\n",
    "        for row in cursor:\n",
    "            try:\n",
    "                row[1] = row[0]        \n",
    "                cursor.updateRow(row)    \n",
    "            except ValueError as error:\n",
    "                print(error)\n",
    "                \n",
    "    #run frequency on output and sum length fields to normalize data by SegmentID\n",
    "    #accounts for lines that may have been split by intersect\n",
    "    print(\"summarize intersect table by SegmentID...\")\n",
    "    freq_output = os.path.join(scratch_gdb_path, \"freq_output\")\n",
    "    freq = arcpy.analysis.Frequency(intersect, freq_output, \"SEGMENTID\", new_length_field)\n",
    "    \n",
    "    #join freq result back to modal comp input dataset\n",
    "    print(\"Join field back to input on SegmentID...\")\n",
    "    join_target = input_dataset\n",
    "    join_target_field = \"SEGMENTID\"\n",
    "    join_table = freq\n",
    "    join_table_field = \"SEGMENTID\"\n",
    "    join_fields = [new_length_field]\n",
    "    \n",
    "    arcpy.JoinField_management(join_target, join_target_field, join_table, join_table_field, join_fields)\n",
    "    \n",
    "    #add new field to input dataset for length % if it doesn't already exist\n",
    "    print(\"add new field for length percentage...\")\n",
    "    list_fields = arcpy.ListFields(input_dataset)\n",
    "    field_names = [i.name for i in list_fields]\n",
    "\n",
    "    if new_percent_field in field_names:\n",
    "        print(\"{} field already exists\".format(new_percent_field))\n",
    "    else:\n",
    "        print(\"adding percent field...\")\n",
    "        arcpy.AddField_management(modal_composite,\n",
    "                                  field_name = new_percent_field,\n",
    "                                  field_type=\"FLOAT\",\n",
    "                                  field_alias = new_percent_alias)\n",
    "\n",
    "    #calculate line percentages based on length differences\n",
    "    #calc field from shape.length with update cursor\n",
    "    print(\"calc percent field...\")\n",
    "    with arcpy.da.UpdateCursor(input_dataset,[new_length_field,\"Shape_Length\",new_percent_field]) as cursor:\n",
    "        for row in cursor:\n",
    "            try:\n",
    "                if row[0] is not None:\n",
    "                    row[2] = row[0]/row[1]  \n",
    "                    \n",
    "                cursor.updateRow(row)    \n",
    "            except ValueError as error:\n",
    "                print(error)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Compute Economic Justice area metrics\n",
    "new_field = \"EJ_percent\"\n",
    "new_alias = \"EJ % by length\"\n",
    "percent(modal_composite, EJ, new_field, new_alias):\n",
    "\n",
    "##Compute Sea Level Rise Exposure Area metrics\n",
    "new_field = \"SLR_percent\"\n",
    "new_alias = \"SLR % by length\"\n",
    "percent(modal_composite, EJ, new_field, new_alias):\n",
    "\n",
    "    \n",
    "print(\"processing complete\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
