{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DTS - Complete Streets\n",
    "\n",
    "# 04a - Modal Composite Development - Step 1\n",
    "\n",
    "**Author:** rmangan\n",
    "\n",
    "---\n",
    "\n",
    "**Purpose:**\n",
    "\n",
    "Compile fields from DTS Sidewalk Inventory, Proposed Sidewalk Improvements, Proposed Sidewalk Additions, Current Bike Facilites, Proposed Bike Facilites, and Redevelopment Bike Facilities to DPP Street Centerline feature class. Datasets are compiled together either by directly joining on SegmentID, or by performing an Intersect, then joining the output using SegmentID\n",
    "\n",
    "**This script performs the following functions:**\n",
    "\n",
    "1. Develop \"Modal Composite 01\" - RCL + Ped data (Sidewalk Inventory, Sidewalk Improvements, Sidewalk Additions) centerline.\n",
    "2. Develop \"Modal Composite 02\" - RCL + Ped + Bike data (Bike Existing, Bike Proposed, Bike Redevelopment)\n",
    "\n",
    "**Global Assumptions and Notes:**\n",
    "1. DPP Street Centerline downloaded 10/13/2020 from http://gis.hicentral.com/gis_layer_list_by_topic_category.html\n",
    "\n",
    "**Non-Standard Python Modules utilized:**\n",
    "1. arcpy 2.7 - used for geoprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import modules\n",
    "import arcpy\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set environment setttings\n",
    "arcpy.env.workspace = \"Z:\\H\\Honolulu_DTS\\D3409300_RailActivation\\GeoData\\GDB\\scratch_GDBs\\modal_composite_scratch.gdb\"\n",
    "arcpy.env.overwriteOutput = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define variables\n",
    "input_gdb_path = r\"\\\\dc1vs01\\GISProj\\H\\Honolulu_DTS\\D3409300_RailActivation\\GeoData\\GDB\\Input_Data.gdb\"\n",
    "\n",
    "scratch_gdb_path = r\"\\\\dc1vs01\\GISProj\\H\\Honolulu_DTS\\D3409300_RailActivation\\GeoData\\GDB\\scratch_GDBs\\modal_composite_scratch.gdb\"\n",
    "\n",
    "output_gdb_path = r\"\\\\dc1vs01\\GISProj\\H\\Honolulu_DTS\\D3409300_RailActivation\\GeoData\\GDB\\scratch_GDBs\\modal_composite_output.gdb\"\n",
    "\n",
    "\n",
    "# Input Datasets\n",
    "Ped_Plan = r\"\\\\dc1vs01\\GISProj\\H\\Honolulu_DTS\\D3409300_RailActivation\\GeoData\\GDB\\scratch_GDBs\\OPP_domain_processing.gdb\\OPP_ModalPriority_081720_output\"\n",
    "\n",
    "Ped_Improve = os.path.join(input_gdb_path,\"OPP_CandidateUpgrades_090420Dissolve_101320\")\n",
    "\n",
    "Ped_Add = os.path.join(input_gdb_path,\"OPP_CandidateWalkways_091520Dissolve_update101620\")\n",
    "\n",
    "Bike_Exist = os.path.join(input_gdb_path,\"BIKEPLAN_Existing_Bikeways\")\n",
    "\n",
    "Bike_Proposed = os.path.join(input_gdb_path,\"BIKEPLAN_Proposed_Bikeways\")\n",
    "\n",
    "Bike_ReDev = os.path.join(input_gdb_path,\"BIKEPLAN_Redevelopment_Bikeways\")\n",
    "\n",
    "RCL = os.path.join(input_gdb_path,\"RCL_Public_Street_Centerline_20201013\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Functions\n",
    "\n",
    "def isUniqueValueField(dataset, field):\n",
    "    #Check if a field is unique for a given dataset, return True/False\n",
    "    idList = []\n",
    "    with arcpy.da.SearchCursor(dataset, field) as cursor:\n",
    "        for row in cursor:\n",
    "            idList.append(row[0])\n",
    "    if len(idList) != len(set(idList)):\n",
    "        return False\n",
    "    else:\n",
    "        return True\n",
    "\n",
    "\n",
    "def LineLength(dataset):\n",
    "    #Add line length field & calculate length. Used to validate geometry is the same after joining\n",
    "    #THIS FUNCTION MODIFIES IT'S INPUT DATASET    \n",
    "    arcpy.AddField_management(dataset, \"line_length\", \"DOUBLE\")\n",
    "    arcpy.CalculateGeometryAttributes_management(dataset,[[\"line_length\", \"LENGTH\"]])\n",
    "    \n",
    "    \n",
    "    \n",
    "def CheckMultiPart(dataset):\n",
    "    #check if a feature class contains multipart geometry, report OIDs of multipart geometry to table\n",
    "    #THIS FUNCTION MODIFIES IT'S INPUT DATASET \n",
    "    \n",
    "    #get count of input features\n",
    "    input_count = arcpy.GetCount_management(dataset)\n",
    "    print(str(input_count) + \" records in input dataset\")\n",
    "\n",
    "    #add tmpUID field to input dataset\n",
    "    arcpy.AddField_management(dataset, \"tmpUID\",\"LONG\")\n",
    "    print(\"tmpUID field added to input dataset\")\n",
    "\n",
    "    #determine OID field of input dataset\n",
    "    OID_field_name = arcpy.Describe(dataset).OIDFieldName\n",
    "    print(\"OID = \" + str(OID_field_name))\n",
    "\n",
    "    #calculate OID to tmpUID\n",
    "    print(\"Calculating OID to tmpUID...\")\n",
    "    arcpy.CalculateField_management(dataset,\"tmpUID\",\"!\" + OID_field_name +\"!\")\n",
    "    print(\"OID calculated to tmpUID\")\n",
    "\n",
    "    #define singlepart dataset\n",
    "    singlepart_fc_name = str(dataset)+\"_singlepart\"\n",
    "    singlepart_fc = os.path.join(scratch_gdb_path, singlepart_fc_name)\n",
    "\n",
    "    #delete singlepart dataset if it already exists\n",
    "    if arcpy.Exists(singlepart_fc):\n",
    "        print(\"Singlepart dataset already exists, deleting...\")\n",
    "        arcpy.Delete_management(singlepart_fc)\n",
    "        print(\"Singlepart dataset deleted\")\n",
    "\n",
    "    #split input features into singlepart dataset\n",
    "    print(\"Splitting input dataset into singlepart feature...\")\n",
    "    arcpy.MultipartToSinglepart_management(dataset,singlepart_fc)\n",
    "    print(\"input exploded to singlepart\" + singlepart_fc_name)\n",
    "\n",
    "    #get feature count of output \n",
    "    output_count = arcpy.GetCount_management(singlepart_fc)\n",
    "    print(str(output_count)+ \" records in singlepart FC\")\n",
    "\n",
    "    # if multipart features found, run freq and get ID of multipart feature\n",
    "    if input_count != output_count:\n",
    "        print(\"Multipart features found.\")\n",
    "        print(\"{0} records in input, {1} records in singlepart output.\".format(input_count, output_count))\n",
    "\n",
    "        #define frequency table\n",
    "        freq_table_name = str(dataset)+\"_freq\"\n",
    "        freq_table = os.path.join(scratch_gdb_path, freq_table_name)\n",
    "\n",
    "        #delete freq table if it already exists\n",
    "        if arcpy.Exists(freq_table):\n",
    "            print(\"freq table exists, deleting...\")\n",
    "            arcpy.Delete_management(freq_table)\n",
    "            print('freq table deleted')\n",
    "\n",
    "        #run frequency analysis on singlepart dataset\n",
    "        print(\"Running frequency analysis...\")\n",
    "        arcpy.Frequency_analysis(singlepart_fc, freq_table, \"tmpUID\")\n",
    "        print(\"frequency analysis complete\")\n",
    "\n",
    "        #print out report of multipart features found\n",
    "        with arcpy.da.SearchCursor(freq_table, ['FREQUENCY','tmpUID'],'\"FREQUENCY\" > 1') as cursor:\n",
    "            for row in cursor:\n",
    "                print(\"Multipart feature found at OID: {}\".format(row[1]))\n",
    "\n",
    "    else:\n",
    "        print(\"No multipart features found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 01 - Develop Modal Composite 01\n",
    "### Load Ped Plan attributes to Street Centerline\n",
    "---\n",
    "\n",
    "Create Modal Composite 01 by loading Ped Plan attributes (Sidewalk Inventory, Ped Improvements, Ped Additions) to DPP Road Centerline.\n",
    "\n",
    "\n",
    "**This section performs the following functions:**\n",
    "\n",
    "1. Add temporary line length fields to input dataset\n",
    "2. Check input datasets for multipart geometry\n",
    "3. Join Ped Sidewalk Inventory to RCL on SegmentID\n",
    "4. Validate joined segments by comparing temporary line length fields\n",
    "\n",
    "**Assumptions and Notes:**\n",
    "1. Field aliases of input Sidewalk Inventory dataset must already be assigned.\n",
    "2. Ped Improvements and Ped Additions datasets are not geometrically identical to RCL. Join is performed by:\n",
    "    1. Spatially intersecting the datasets together to create join key\n",
    "    2. Joining the intersect output back to RCL on SegmentID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#step 1\n",
    "\n",
    "#copy feature classes to scratch gdb for processing\n",
    "print(\"Copying RCL to scratch gdb...\")\n",
    "RCL_temp = arcpy.CopyFeatures_management(RCL,(os.path.join(scratch_gdb_path, \"RCL_temp\")))\n",
    "print(\"Done\")\n",
    "\n",
    "print(\"Copying Ped Data to scratch gdb...\")\n",
    "ped_temp = arcpy.CopyFeatures_management(Ped_Plan,(os.path.join(scratch_gdb_path, \"Ped_temp2\")))\n",
    "print(\"Done\")\n",
    "\n",
    "#add & calculate line_length fields\n",
    "print(\"Adding line length fields to datasets...\")\n",
    "LineLength(RCL_temp)\n",
    "LineLength(ped_temp)\n",
    "print(\"Done\")\n",
    "\n",
    "#check for multipart geometry\n",
    "CheckMultiPart(RCL_temp)\n",
    "CheckMultiPart(ped_temp)\n",
    "\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#step 2\n",
    "\n",
    "#copy RCL_temp to serve as join target and as output modal_composite_01 dataset\n",
    "print(\"Copying RCL_temp to serve as modal composite_01 join target...\")\n",
    "modal_composite_01 = arcpy.CopyFeatures_management(RCL_temp,(os.path.join(scratch_gdb_path, \"modal_composite_01\")))\n",
    "print(\"Copying complete.\")\n",
    "\n",
    "#join fields from ped_temp to modal_composite 01\n",
    "join_target = modal_composite_01\n",
    "join_target_field = \"SEGMENTID\"\n",
    "join_table = ped_temp\n",
    "join_table_field = \"SEGMENTID\"\n",
    "join_fields = [\n",
    "    \"NBRightPed\",\"SBLeftPedZ\",\"NBRightP_1\",\"SBLeftPe_1\",\"NBRightP_2\",\n",
    "    \"SBLeftPe_2\",\"NBRightP_3\",\"SBLeftPe_3\",\"NBRightP_4\",\"SBLeftPe_4\",\n",
    "    \"NBRightP_5\",\"SBLeftPedB\",\"NBRightP_6\",\"SBLeftPe_5\",\"NBRightP_7\",\n",
    "    \"SBLeftPe_6\",\"NBRightP_8\",\"SBLeftPe_7\",\"NBRightVis\",\"SBLeftVisu\",\n",
    "    \"MidBlkXwkU\",\"MidBlkXwkC\",\"MidBlkXw_1\",\"TraffCalmi\",\"PPN_Final\",\n",
    "    \"HPI\",\"PpnNotCity\",\"line_length\"\n",
    "]\n",
    "\n",
    "print(\"Joining fields...\")\n",
    "arcpy.JoinField_management(join_target, join_target_field, join_table, join_table_field, join_fields)\n",
    "print(\"Join Fields complete.\")\n",
    "\n",
    "#assign domains to fields\n",
    "#store field/domain mapping in a dict, field name is key, domain table is value\n",
    "ped_domain_mapping = {\n",
    "    \"SBLeftPe_6\": \"OPP_domain_PedBuffRdBuff\",\n",
    "    \"NBRightP_8\": \"OPP_domain_PedBuffLight\",\n",
    "    \"NBRightP_7\": \"OPP_domain_PedBuffRdBuff\",\n",
    "    \"SBLeftPe_5\": \"OPP_domain_PedBuffTree\",\n",
    "    \"NBRightP_6\": \"OPP_domain_PedBuffTree\",\n",
    "    \"SBLeftPedB\": \"OPP_domain_PedBuffFrn\",\n",
    "    \"NBRightP_5\": \"OPP_domain_PedBuffFrn\",\n",
    "    \"SBLeftPe_4\": \"OPP_domain_PedZoneInt\",\n",
    "    \"NBRightP_4\": \"OPP_domain_PedZoneInt\",\n",
    "    \"SBLeftPe_3\": \"OPP_domain_PedZoneCond\",\n",
    "    \"NBRightP_3\": \"OPP_domain_PedZoneCond\",\n",
    "    \"SBLeftPe_2\": \"OPP_domain_PedZoneWidth\",\n",
    "    \"NBRightP_2\": \"OPP_domain_PedZoneDrvycut\",\n",
    "    \"SBLeftPe_1\": \"OPP_domain_PedZoneWidth\",\n",
    "    \"NBRightP_1\": \"OPP_domain_PedZoneWidth\",\n",
    "    \"SBLeftPedZ\": \"OPP_domain_PedZoneType\",\n",
    "    \"NBRightPed\": \"OPP_domain_PedZoneType\",\n",
    "    \"SBLeftPe_7\": \"OPP_domain_PedBuffLight\",\n",
    "    \"NBRightVis\": \"OPP_domain_VisualInterest\",\n",
    "    \"SBLeftVisu\": \"OPP_domain_VisualInterest\",\n",
    "    \"MidBlkXwkU\": \"OPP_domain_MidBlkXwkUse\",\n",
    "    \"MidBlkXwkC\": \"OPP_domain_MidBlkXwkCond\",\n",
    "    \"MidBlkXw_1\": \"OPP_domain_MidBlkXwkCntrl\",\n",
    "    \"TraffCalmi\": \"OPP_domain_TraffCalming\"}\n",
    "\n",
    "#iterate through domain dict and assign domains to newly joined fields\n",
    "for key, value in ped_domain_mapping.items():\n",
    "    print(\"assigning domain {} to field {}\".format(value,key))\n",
    "    print(\"Done\")\n",
    "    arcpy.management.AssignDomainToField(modal_composite_01, key, value)    \n",
    "print(\"Domain Assignment Complete\")\n",
    "\n",
    "\n",
    "#print out report of different line length segments (only needed if multipart QC was run)\n",
    "with arcpy.da.SearchCursor(modal_composite_01, ['OBJECTID','line_length', 'line_length_1'],'\"line_length\" <> \"line_length_1\"') as cursor:\n",
    "    for row in cursor:\n",
    "        print(\"Length difference found at OID: {}\".format(row[0]))\n",
    "        \n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#step 3 -join validation (optional)\n",
    "#modal features with no join targes are stored in ped_temp_join_validation as \"SEGMENTID_1\" IS NULL\n",
    "\n",
    "#copy ped_temp for join validation\n",
    "print(\"Copying ped_temp to validate join...\")\n",
    "ped_temp_join_validation = arcpy.CopyFeatures_management(ped_temp,(os.path.join(scratch_gdb_path, \"ped_temp_join_validation\")))\n",
    "\n",
    "# join rcl to modal\n",
    "join_target = ped_temp_join_validation\n",
    "join_target_field = \"SEGMENTID\"\n",
    "join_table = RCL_temp\n",
    "join_table_field = \"SEGMENTID\"\n",
    "join_fields = [\"SEGMENTID\"]\n",
    "\n",
    "print(\"Joining fields...\")\n",
    "arcpy.JoinField_management(join_target, join_target_field, join_table, join_table_field, join_fields)\n",
    "print(\"Join Fields complete.\")\n",
    "\n",
    "#print out report of modal features with no valid join targets\n",
    "with arcpy.da.SearchCursor(ped_temp_join_validation, ['OBJECTID','SEGMENTID', 'SEGMENTID_1'],'\"SEGMENTID_1\" IS NULL') as cursor:\n",
    "    for row in cursor:\n",
    "        print(\"No join targets in RCL for ObjectID: {}, SEGMENTID: {}\".format(row[0],row[1]))\n",
    "        \n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#step 4 - join Ped Plan - Upgrades & New Features to RCL\n",
    "\n",
    "# inputs are not geometrically identical to RCL (new sidewalk data spans multiple RCL segments)\n",
    "# join performed via spatial intersect to split lines by segements & assigning segmentIDs for join key\n",
    "\n",
    "#copy inputs to scratch gdb for processing\n",
    "print(\"Copying Ped Improve to scratch gdb...\")\n",
    "Ped_Improve_temp = arcpy.CopyFeatures_management(Ped_Improve,(os.path.join(scratch_gdb_path, \"Ped_Improve_temp\")))\n",
    "print(\"Done\")\n",
    "\n",
    "print(\"Copying Ped Upgrade to scratch gdb...\")\n",
    "Ped_Add_temp = arcpy.CopyFeatures_management(Ped_Add,(os.path.join(scratch_gdb_path, \"Ped_Add_temp\")))\n",
    "print(\"Done\")\n",
    "\n",
    "#intesect Ped datsets with RCL\n",
    "print(\"Running Ped Improvement intersect...\")\n",
    "Ped_Improve_intersect = arcpy.Intersect_analysis([Ped_Improve_temp, RCL_temp],(os.path.join(scratch_gdb_path, \"Ped_Improve_intersect\")))\n",
    "print(\"Done\")\n",
    "\n",
    "print(\"Running Ped Add intersect...\")\n",
    "Ped_Add_intersect = arcpy.Intersect_analysis([Ped_Add_temp, RCL_temp],(os.path.join(scratch_gdb_path, \"Ped_Add_RCL_intersect\")))\n",
    "print(\"Done\")\n",
    "\n",
    "#join target\n",
    "join_target = modal_composite_01\n",
    "join_target_field = \"SEGMENTID\"\n",
    "\n",
    "#join Ped Improvement Interserct Results to RCL...\n",
    "print(\"Joining Ped Improvement fields...\")\n",
    "join_table = Ped_Improve_intersect\n",
    "join_table_field = \"SEGMENTID\"\n",
    "join_fields = [\"FID_Ped_Improve_temp\",\n",
    "               \"ProjectID\",\n",
    "               \"Extents\"]\n",
    "\n",
    "arcpy.JoinField_management(join_target, join_target_field, join_table, join_table_field, join_fields)\n",
    "print(\"Join Fields complete.\")\n",
    "\n",
    "#join Ped Additions Intersect Results to RCL...\n",
    "print(\"Joining Ped Additions fields...\")\n",
    "join_table = Ped_Add_intersect\n",
    "join_table_field = \"SEGMENTID\"\n",
    "join_fields = [\"FID_Ped_Add_temp\",\n",
    "               \"ProjectID\",\n",
    "               \"Extents\"]\n",
    "\n",
    "arcpy.JoinField_management(join_target, join_target_field, join_table, join_table_field, join_fields)\n",
    "print(\"Join Fields complete.\")\n",
    "\n",
    "#modify fields that imported with duplicate names\n",
    "renamed_fields = {\"ProjectID\":\"Ped_Improve_ProjectID\",\n",
    "                  \"Extents\":\"Ped_Immprove_Extents\",\n",
    "                  \"ProjectID_1\":\"Ped_Add_Project_ID\",\n",
    "                  \"Extents_1\":\"Ped_Add_Extents\"}\n",
    "\n",
    "for key, value in renamed_fields.items():\n",
    "    print(\"renaming field {} to field {}\".format(key,value))\n",
    "    arcpy.AlterField_management(modal_composite_01, key, value)\n",
    "\n",
    "print(\"done\")\n",
    "\n",
    "print(\"Modal Composite 01 - Complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 02 - Develop Modal Composite 02\n",
    "### Load Bike Plan attributes onto Street Centerline\n",
    "\n",
    "---\n",
    "\n",
    "Create Modal Composite 02 by loading Bike Plan (existing, proposed, redevelopment) attributes to Modal Composite 01\n",
    "\n",
    "\n",
    "**This section performs the following functions:**\n",
    "\n",
    "1. Copy DTS inputs to scratch gdb for processing\n",
    "2. Assign field aliases to bike fields using dictionary\n",
    "3. Intersect bike datasets with RCL\n",
    "4. Join intersect outputs back to modal_composite_01 to create modal_composite_02\n",
    "\n",
    "**Assumptions and Notes:**\n",
    "1. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#step 1 - copy inputs to scratch gdb and pre-process each dataset prior to joining to RCL\n",
    "\n",
    "#copy Bike Plan Datsets to scratch for processing\n",
    "print(\"Copying Bike Existing to scratch gdb...\")\n",
    "Bike_Exist_temp = arcpy.CopyFeatures_management(Bike_Exist,(os.path.join(scratch_gdb_path, \"Bike_Exist_temp\")))\n",
    "print(\"Done\")\n",
    "\n",
    "print(\"Copying Bike Proposed to scratch gdb...\")\n",
    "Bike_Proposed_temp = arcpy.CopyFeatures_management(Bike_Proposed,(os.path.join(scratch_gdb_path, \"Bike_Proposed_temp\")))\n",
    "print(\"Done\")\n",
    "\n",
    "print(\"Copying Bike ReDev to scratch gdb...\")\n",
    "Bike_ReDev_temp = arcpy.CopyFeatures_management(Bike_ReDev,(os.path.join(scratch_gdb_path, \"Bike_ReDev_temp\")))\n",
    "print(\"Done\")\n",
    "\n",
    "#store field, field aliases mappings in a dict\n",
    "bike_exist_alias = {\n",
    "    \"Fac_Name\":\"Facility Name (Bike Existing)\",\n",
    "    \"Fac_Desc\":\"Facility Description (Bike Existing)\",\n",
    "    \"Fac_Type\":\"Facility Type (Bike Existing)\",\n",
    "    \"Length_mi\":\"Length (miles) (Bike Existing)\",   \n",
    "    \"Owner\":\"Owner (Bike Existing)\",\n",
    "    \"DP_area\":\"DP Area (Bike Existing)\"\n",
    "}\n",
    "\n",
    "bike_proposed_alias = {\n",
    "    \"Project_ID\":\"Project ID (Bike Proposed)\",\n",
    "    \"Fac_Name\":\"Facility Name (Bike Proposed)\",\n",
    "    \"Fac_Desc\":\"Facility Description (Bike Proposed)\",\n",
    "    \"Fac_Type\":\"Facility Type (Bike Proposed)\",\n",
    "    \"length_mi\":\"Length (miles) (Bike Proposed)\",\n",
    "    \"Owner\":\"Owner (Bike Proposed)\",\n",
    "    \"DP_area\":\"DP Area (Bike Proposed)\",\n",
    "    \"Priority\":\"Priority (Bike Proposed)\",\n",
    "    \"Cost_Est\":\"Cost Estimate (Bike Proposed)\"\n",
    "}\n",
    "\n",
    "bike_redev_alias = {\n",
    "    \"ProjectID\":\"Project ID (Bike ReDev)\",\n",
    "    \"Fac_Name\":\"Facility Name (Bike ReDev)\",\n",
    "    \"Fac_Desc\":\"Facitlity Description (Bike ReDev)\",\n",
    "    \"Fac_Type\":\"Facility Type (Bike ReDev)\",\n",
    "    \"Length_mi\":\"Length (miles) (Bike ReDev)\",\n",
    "    \"Owner\":\"Owner (Bike ReDev)\",\n",
    "    \"DP_area\":\"DP Area (Bike ReDev)\"    \n",
    "}\n",
    "\n",
    "#loop throug dicts and assign aliases & rename fields for each dataset\n",
    "\n",
    "#bike existing\n",
    "for key, value in bike_exist_alias.items():\n",
    "    new_field_name = str(key)+\"_BE\"\n",
    "    print(\"assigning alias {} to field {}, field renamed to {}\".format(value,key,new_field_name))\n",
    "    arcpy.AlterField_management(Bike_Exist_temp,key,new_field_name, value)    \n",
    "print(\"Done\")\n",
    "\n",
    "#bike proposed\n",
    "for key, value in bike_proposed_alias.items():\n",
    "    new_field_name = str(key)+\"_BP\"\n",
    "    print(\"assigning alias {} to field {}, field renamed to {}\".format(value,key,new_field_name))\n",
    "    arcpy.AlterField_management(Bike_Proposed_temp,key,new_field_name, value)    \n",
    "print(\"Done\")\n",
    "\n",
    "#bike redevelopment\n",
    "for key, value in bike_redev_alias.items():\n",
    "    new_field_name = str(key)+\"_BR\"\n",
    "    print(\"assigning alias {} to field {}, field renamed to {}\".format(value,key,new_field_name))\n",
    "    arcpy.AlterField_management(Bike_ReDev_temp,key,new_field_name, value)    \n",
    "print(\"Done\")\n",
    "                   \n",
    "print(\"Bike input processing Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#step 02 - intersect datasets with RCL and load attributes from output by joining on SegmentID\n",
    "\n",
    "#intesect bike datsets with RCl\n",
    "print(\"Running Bike Exist intersect...\")\n",
    "Bike_Exist_RCL_intersect = arcpy.Intersect_analysis([Bike_Exist_temp, RCL_temp],(os.path.join(scratch_gdb_path, \"Bike_Exist_RCL_intersect\")))\n",
    "\n",
    "print(\"Running Bike Proposed intersect...\")\n",
    "Bike_Proposed_RCL_intersect = arcpy.Intersect_analysis([Bike_Proposed_temp, RCL_temp],(os.path.join(scratch_gdb_path, \"Bike_Proposed_RCL_intersect\")))\n",
    "\n",
    "print(\"Running Bike ReDev intersect...\")\n",
    "Bike_ReDev_RCL_intersect = arcpy.Intersect_analysis([Bike_ReDev_temp, RCL_temp],(os.path.join(scratch_gdb_path, \"Bike_ReDev_RCL_intersect\")))\n",
    "print(\"Done\")\n",
    "   \n",
    "#join fields from resultant to modal composite\n",
    "\n",
    "#create modal_composite 02 from  modal_composite_01\n",
    "print(\"Copying modal_composite_01 to serve as modal composite join target...\")\n",
    "modal_composite_02 = arcpy.CopyFeatures_management(modal_composite_01,(os.path.join(scratch_gdb_path, \"modal_composite_02\")))\n",
    "print(\"Copying complete.\")\n",
    "\n",
    "#reassign domains (may not be needed)\n",
    "#store field/domain mapping in a dict, field name is key, domain table is value\n",
    "ped_domain_mapping = {\n",
    "    \"SBLeftPe_6\": \"OPP_domain_PedBuffRdBuff\",\n",
    "    \"NBRightP_8\": \"OPP_domain_PedBuffLight\",\n",
    "    \"NBRightP_7\": \"OPP_domain_PedBuffRdBuff\",\n",
    "    \"SBLeftPe_5\": \"OPP_domain_PedBuffTree\",\n",
    "    \"NBRightP_6\": \"OPP_domain_PedBuffTree\",\n",
    "    \"SBLeftPedB\": \"OPP_domain_PedBuffFrn\",\n",
    "    \"NBRightP_5\": \"OPP_domain_PedBuffFrn\",\n",
    "    \"SBLeftPe_4\": \"OPP_domain_PedZoneInt\",\n",
    "    \"NBRightP_4\": \"OPP_domain_PedZoneInt\",\n",
    "    \"SBLeftPe_3\": \"OPP_domain_PedZoneCond\",\n",
    "    \"NBRightP_3\": \"OPP_domain_PedZoneCond\",\n",
    "    \"SBLeftPe_2\": \"OPP_domain_PedZoneWidth\",\n",
    "    \"NBRightP_2\": \"OPP_domain_PedZoneDrvycut\",\n",
    "    \"SBLeftPe_1\": \"OPP_domain_PedZoneWidth\",\n",
    "    \"NBRightP_1\": \"OPP_domain_PedZoneWidth\",\n",
    "    \"SBLeftPedZ\": \"OPP_domain_PedZoneType\",\n",
    "    \"NBRightPed\": \"OPP_domain_PedZoneType\",\n",
    "    \"SBLeftPe_7\": \"OPP_domain_PedBuffLight\",\n",
    "    \"NBRightVis\": \"OPP_domain_VisualInterest\",\n",
    "    \"SBLeftVisu\": \"OPP_domain_VisualInterest\",\n",
    "    \"MidBlkXwkU\": \"OPP_domain_MidBlkXwkUse\",\n",
    "    \"MidBlkXwkC\": \"OPP_domain_MidBlkXwkCond\",\n",
    "    \"MidBlkXw_1\": \"OPP_domain_MidBlkXwkCntrl\",\n",
    "    \"TraffCalmi\": \"OPP_domain_TraffCalming\"}\n",
    "\n",
    "#iterate through domain dict and assign domains to newly joined fields\n",
    "for key, value in ped_domain_mapping.items():\n",
    "    print(\"assigning domain {} to field {}\".format(value,key))\n",
    "    print(\"Done\")\n",
    "    arcpy.management.AssignDomainToField(modal_composite_02, key, value)\n",
    "    \n",
    "print(\"Domain Assignment Complete\")\n",
    "                                        \n",
    "#join fields from Bike Existing to modal_composite test layer\n",
    "join_target = modal_composite_02\n",
    "join_target_field = \"SEGMENTID\"\n",
    "\n",
    "#join Bike Existing intersect results\n",
    "print(\"Joining Bike Existing fields...\")\n",
    "join_table = Bike_Exist_RCL_intersect\n",
    "join_table_field = \"SEGMENTID\"\n",
    "join_fields = [\"Fac_Name_BE\",\n",
    "               \"Fac_Desc_BE\",\n",
    "               \"DP_area_BE\",\n",
    "               \"Fac_Type_BE\",\n",
    "               \"Length_mi_BE\",\n",
    "               \"Owner_BE\"]\n",
    "\n",
    "arcpy.JoinField_management(join_target, join_target_field, join_table, join_table_field, join_fields)\n",
    "print(\"Join Fields complete.\")\n",
    "\n",
    "#join Bike Proposed intersect results\n",
    "print(\"Joining Bike Proposed fields...\")\n",
    "join_table = Bike_Proposed_RCL_intersect\n",
    "join_table_field = \"SEGMENTID\"\n",
    "join_fields = [\"Fac_Name_BP\",\n",
    "               \"Fac_Desc_BP\",\n",
    "               \"length_mi_BP\",\n",
    "               \"DP_area_BP\",\n",
    "               \"Project_ID_BP\",\n",
    "               \"Fac_Type_BP\",\n",
    "               \"Priority_BP\"\n",
    "               \"Owner_BP\",\n",
    "               \"Cost_Est_BP\"]\n",
    "\n",
    "arcpy.JoinField_management(join_target, join_target_field, join_table, join_table_field, join_fields)\n",
    "print(\"Join Fields complete.\")\n",
    "\n",
    "#join Bike ReDev intersect results\n",
    "print(\"Joining Bike ReDev fields...\")\n",
    "join_table = Bike_ReDev_RCL_intersect\n",
    "join_table_field = \"SEGMENTID\"\n",
    "join_fields = [\"Fac_Name_BR\",\n",
    "               \"Fac_Desc_BR\",\n",
    "               \"Project_ID_BR\",\n",
    "               \"DP_area_BR\",\n",
    "               \"Length_mi_BR\",\n",
    "               \"Fac_Type_BR\",\n",
    "               \"Owner_BR\"]\n",
    "\n",
    "arcpy.JoinField_management(join_target, join_target_field, join_table, join_table_field, join_fields)\n",
    "print(\"Join Fields complete.\")\n",
    "\n",
    "print(\"Bike Processing Complete\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## QC functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#list records of different line length\n",
    "\n",
    "#print out report of multipart features found\n",
    "with arcpy.da.SearchCursor(ped_temp_join_validation, ['OBJECTID','SEGMENTID', 'SEGMENTID_1'],'\"SEGMENTID_1\" IS NULL') as cursor:\n",
    "    for row in cursor:\n",
    "        print(\"No join targets in RCL for ObjectID: {}, SEGMENTID: {}\".format(row[0],row[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PED re-copy to scratch - rerun as needed\n",
    "\n",
    "#1) copy feature classes to scratch gdb for processing\n",
    "ped_temp = arcpy.CopyFeatures_management(Ped_Plan,(os.path.join(scratch_gdb_path, \"Ped_temp\")))\n",
    "\n",
    "#2) add & calculate line_length fields\n",
    "LineLength(ped_temp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## 1986 ROW dataset field parsing (MOVE TO DIFFERENT NOTEBOOK)\n",
    "\n",
    "**Summary**  \n",
    "blah blah blah\n",
    "\n",
    "**Details**  \n",
    "blah blah blah\n",
    "\n",
    "\n",
    "**Assumptions**  \n",
    "blah blah blah\n",
    "\n",
    "**Code Snippet**  \n",
    "> code goes here\n",
    "\n",
    "**Links**  \n",
    "[enter link description here](www.google.com)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#create num fields from 1986 text fields & parse value to new fields handle text entry via hardcoded mapping\n",
    "\n",
    "#copy input dataset while testing functions\n",
    "print(\"copying modal input for processing...\")\n",
    "modal_processing_temp = arcpy.CopyFeatures_management(modal_composite_03,\"modal_processing_temp\")\n",
    "print(\"done\")\n",
    "\n",
    "#store field, field alias in dict\n",
    "new_fields = {\"ln_exist_num\":\"1986 Existing Lanes (num)\",\n",
    "              \"ln_prop_num\": \"1986 Proposed Lanes (num)\",\n",
    "              \"row_exist_num\":\"1986 Existing ROW (num)\",\n",
    "              \"row_prop_num\":\"1986 Proposed ROW (num)\"}\n",
    "\n",
    "#loop through dict and add fields\n",
    "for key,value in new_fields.items():\n",
    "    print(\"Adding field {0}\".format(key))\n",
    "    arcpy.AddField_management(modal_processing_temp,field_name=key,field_type=\"SHORT\", field_alias = value)\n",
    "          \n",
    "print(\"Field additions complete\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#field to expose to update cursor\n",
    "fields = [\"ln_exist\",\"ln_prop\",\"row_exist\",\"row_prop\",\"ln_exist_num\",\"ln_prop_num\", \"row_exist_num\",\"row_prop_num\"]\n",
    "\n",
    "#update ln_exist_num w/ update cursor\n",
    "print(\"parse ln_exist to int\")\n",
    "with arcpy.da.UpdateCursor(modal_processing_temp,fields,'NOT \"ln_exist\" IS NULL') as cursor:\n",
    "    for row in cursor:\n",
    "        #print(\"row\")\n",
    "        try:\n",
    "            if row[0] == '4+ bus':\n",
    "                row[4] = 4\n",
    "            elif row[0] == '3+ bus':\n",
    "                row[4] = 3\n",
    "            else:\n",
    "                row[4]= int(row[0])\n",
    "            cursor.updateRow(row)\n",
    "        except ValueError as error:\n",
    "            print(error)            \n",
    "print(\"ln_exist parsed\\n\")\n",
    "            \n",
    "#update ln_prop_num w/ update cursor\n",
    "print(\"parse ln_prop to int\")\n",
    "with arcpy.da.UpdateCursor(modal_processing_temp,fields,'NOT \"ln_exist\" IS NULL') as cursor:\n",
    "    for row in cursor:\n",
    "        #print(\"row\")\n",
    "        try:\n",
    "            if row[1] == '5+ bus':\n",
    "                row[5] = 5\n",
    "            else:\n",
    "                row[5]= int(row[1])\n",
    "            cursor.updateRow(row)\n",
    "        except ValueError as error:\n",
    "            print(error)\n",
    "print(\"ln_prop parsed\\n\")\n",
    "            \n",
    "#update row_exist_num w/ update cursor\n",
    "print(\"parse row_exist to num\")\n",
    "with arcpy.da.UpdateCursor(modal_processing_temp,fields,'NOT \"ln_exist\" IS NULL') as cursor:\n",
    "    for row in cursor:\n",
    "        #print(\"row\")\n",
    "        try:\n",
    "            if row[2] == 'Var. to 80':\n",
    "                row[6] = 80\n",
    "            elif row[2] == 'Var. 60-70':\n",
    "                row[6] = 65\n",
    "            elif row[2] == 'Var. 36-50':\n",
    "                row[6] == 61\n",
    "            elif row[2] == 'Var. 14-26':\n",
    "                row[6] = 20\n",
    "            elif row[2] == '86/100':\n",
    "                row[6] = 93\n",
    "            elif row[2] == '60-90':\n",
    "                row[6] = 75\n",
    "            elif row[2] == '60-76':\n",
    "                row[6] = 68\n",
    "            elif row[2] == '60-70':\n",
    "                row[6] = 65\n",
    "            elif row[2] == '60-64':\n",
    "                row[6] = 62\n",
    "            elif row[2] == '50-80':\n",
    "                row[6] = 65\n",
    "            elif row[2] == '50-60':\n",
    "                row[6] = 55\n",
    "            elif row[2] == '44-56':\n",
    "                row[6] = 50\n",
    "            elif row[2] == '40/50':\n",
    "                row[6] = 45\n",
    "            elif row[2] == '40-56':\n",
    "                row[6] = 48\n",
    "            elif row[2] == '30-50':\n",
    "                row[6] = 40\n",
    "            elif row[2] == '30-40':\n",
    "                row[6] = 35\n",
    "            elif row[2] == '25-50':\n",
    "                row[6] = 38\n",
    "            elif row[2] == '20-40':\n",
    "                row[6] = 30\n",
    "            elif row[2] == '25-50':\n",
    "                row[6] = 38\n",
    "            elif row[2] == '120-140':\n",
    "                row[6] = 130\n",
    "            elif row[2] == '113.5':\n",
    "                row[6] = 114\n",
    "            elif row[2] == '100-110':\n",
    "                row[6] = 105\n",
    "            elif row[2] == '0':\n",
    "                row[6] = None\n",
    "            else:\n",
    "                row[6]= int(row[2])\n",
    "            cursor.updateRow(row)\n",
    "        except ValueError as error:\n",
    "            print(error)\n",
    "print(\"row_exist parsed\\n\")            \n",
    "                  \n",
    "#update row_prop_num w/ update cursor\n",
    "print(\"parse row_prop to int\")\n",
    "with arcpy.da.UpdateCursor(modal_processing_temp,fields,'NOT \"ln_exist\" IS NULL') as cursor:\n",
    "    for row in cursor:\n",
    "        #print(\"row\")\n",
    "        try:          \n",
    "            if row[3] == 'Var. to 80':\n",
    "                row[7] = 80\n",
    "            elif row[3] == 'Var. 14-26':\n",
    "                row[7] = 20\n",
    "            elif row[3] == '86/100':\n",
    "                row[7] = 93\n",
    "            elif row[3] == '60-90':\n",
    "                row[7] = 75\n",
    "            elif row[3] == '60-76':\n",
    "                row[7] = 68\n",
    "            elif row[3] == '60-70':\n",
    "                row[7] = 65\n",
    "            elif row[3] == '60-64':\n",
    "                row[7] = 62\n",
    "            elif row[3] == '56-80':\n",
    "                row[7] = 68\n",
    "            elif row[3] == '50-60':\n",
    "                row[7] = 55\n",
    "            elif row[3] == '40/50':\n",
    "                row[7] = 45\n",
    "            elif row[3] == '30-40':\n",
    "                row[7] = 35\n",
    "            elif row[3] == '25-50':\n",
    "                row[7] = 38\n",
    "            elif row[3] == '120-140':\n",
    "                row[7] = 130\n",
    "            elif row[3] == '113.5':\n",
    "                row[7] = 114\n",
    "            elif row[3] == '100-110':\n",
    "                row[7] = 105\n",
    "            else:\n",
    "                row[7] = int(row[3])\n",
    "            cursor.updateRow(row)\n",
    "        except ValueError as error:\n",
    "            print(error)\n",
    "print(\"row_prop parsed\\n\")\n",
    "\n",
    "print(\"Processing Complete\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
